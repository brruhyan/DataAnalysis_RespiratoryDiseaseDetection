# -*- coding: utf-8 -*-
"""Personal Project: Model Deployment

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wo67bS_9PWrj6LcjLTVroFOKvmG6t-wC

Data Analysis Personal Project | Respiratory Disease Detection
--- | ---
<hr> | <hr>
**Name** | de Leon, Bryan Paul <br>
**Date** | May 28, 2024

# PART 1: The Dataset

**About the Project**
- A personal project wherein I developed and trained a Convolution Neural Network for the purpose of being able to insert images through Streamlit, the model will then determine if the X-ray image inserted into the app displays sign of a Respiratory Condition.

**Dataset Source**
- [Respiratory Image Dataset](https://www.kaggle.com/datasets/fatemehmehrparvar/lung-disease)
"""

#importing necessary libraries

from sklearn.metrics import confusion_matrix
from keras.models import Sequential
from keras.layers import Dense, Input, Activation
from keras.utils import to_categorical
import pandas as pd
import matplotlib.pyplot as plt
import zipfile
import os

#mounting the dataset into colab

from google.colab import drive
drive.mount('/content/drive')

#navigating to the dataset

data_directory_train = ('//content/drive/MyDrive/DATASET/RESPIRATORY')
filepaths = []
labels = []
folds = os.listdir(data_directory_train)

for fold in folds:
  fold_path = os.path.join(data_directory_train, fold)
  filelists = os.listdir(fold_path)

  for file in filelists:
    file_path = os.path.join(fold_path, file)

    filepaths.append(file_path)
    labels.append(fold)

#storing the images into a dataframe for training data

Fdata_train = pd.Series(filepaths, name = 'filename')
Ldata_train = pd.Series(labels, name = 'label')

respiratoryFrame = pd.concat([Fdata_train, Ldata_train], axis = 1)

#verfying changes for training set

respiratoryFrame.head()

respiratoryFrame.info()

"""# PART 2: Data Processing"""

#importing necessary libraries

from sklearn.model_selection import train_test_split
from keras.preprocessing.image import ImageDataGenerator

#splitting the data into training and testing

train_data, dummy_data = train_test_split(respiratoryFrame, train_size = 0.4, shuffle = True, random_state = 42,
                                          stratify = respiratoryFrame['label'] )

valid_data, test_data = train_test_split(dummy_data, train_size = 0.4, shuffle = True, random_state = 42,
                                         stratify = dummy_data['label'])

#performing image augmentation

datagen = ImageDataGenerator(

    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,

)

#applying image augmentation into the datasets

train_generator = datagen.flow_from_dataframe(
    dataframe = train_data,
    x_col='filename',
    y_col='label',
    featurewise_center=True,
    zca_whitening = True,
    target_size=(150,150),
    batch_size=128,
    class_mode='categorical'
)

valid_generator = datagen.flow_from_dataframe(
    dataframe=valid_data,
    x_col='filename',
    y_col='label',
    target_size=(150,150),
    batch_size=128,
    class_mode='categorical'
)

test_generator = datagen.flow_from_dataframe(
    dataframe=test_data,
    x_col='filename',
    y_col='label',
    target_size=(150,150),
    batch_size=128,
    class_mode='categorical',
    shuffle=False
)

"""# PART 3: Creating the CNN Model"""

#importing necessary libraries

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.optimizers import SGD, Adam

#defining the CNN Model

model = Sequential([
    Conv2D(256, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(150,150,3)),
    MaxPooling2D((3, 3)),
    Conv2D(128, (2, 2), activation='relu', kernel_initializer='he_uniform'),
    MaxPooling2D((3, 3)),
    Dropout(0.2),
    Flatten(),
    Dense(256, activation='relu'),
    Dense(256, activation='relu'),
    Dense(32, activation='relu'),
    Dense(2, activation='sigmoid') # 2 output layer for 2 categories
])

#compiling the model

model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

#fitting the model

hist = model.fit(
    train_generator,
    steps_per_epoch = len(train_generator),
    epochs = 15,
    validation_data = valid_generator,
    validation_steps = len(valid_generator)
)

#evaluate the performance of the model

model.evaluate(test_generator)

model.evaluate(valid_generator)

#plotting the training and testing

hist.history.keys()

plt.plot(hist.history['accuracy'], label = 'accuracy')
plt.plot(hist.history['val_accuracy'], label = 'validation accuracy')

plt.legend()
plt.show()

"""# PART 4: Saving Model"""

from google.colab import drive
drive.mount('/content/drive')

#importing libraries

!pip install h5py
from keras.models import load_model, save_model

#saving the model that we made into hdf5 format

model.save('respiratory_trained.h5')

"""# PART 5: Model Deployment


"""

!pip install streamlit

# Commented out IPython magic to ensure Python compatibility.
# #creating the app py
# 
# %%writefile app.py
# 
# import streamlit as st
# import tensorflow as tf
# import numpy as np
# 
# @st.cache_resource
# def load_model():
#   model=tf.keras.models.load_model('respiratory_trained')
#   return model
# model=load_model()
# st.write("""
# # Respiratory Disease Detection"""
# )
# file=st.file_uploader("Insert Chest X-ray",type=["jpg","png"])
# 
# import cv2
# from PIL import Image,ImageOps
# import numpy as np
# def import_and_predict(image_data,model):
#     size=(150,150)
#     image=ImageOps.fit(image_data,size, Image.Resampling.LANCZOS)
#     img=np.asarray(image)
#     img_reshape=img[np.newaxis,...]
#     prediction=model.predict(img_reshape)
#     return prediction
# if file is None:
#     st.text("Please upload an image file")
# else:
#     image=Image.open(file)
#     st.image(image,use_column_width=True)
#     prediction=import_and_predict(image,model)
#     class_names=['Normal', 'Viral Pneumonia']
#     string="OUTPUT : "+class_names[np.argmax(prediction)]
#     st.success(string)